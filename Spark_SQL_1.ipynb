{"cells":[{"cell_type":"markdown","metadata":{"id":"IhqAQ_OOKTXl"},"source":["# **Spark SQL Básico**"]},{"cell_type":"markdown","metadata":{"id":"_zJeZZqpJu73"},"source":["## Introducción"]},{"cell_type":"markdown","metadata":{"id":"Ojkkv5J5rwg-"},"source":["### `Ventajas y desventajas de trabajar con Spark en Google Colab`"]},{"cell_type":"markdown","metadata":{"id":"AzJLfwssmyU6"},"source":["Ventajas:\n","- Fácil acceso\n","- Ejecutar Spark en prácticamente cualquier dispositivo, los recursos están en la nube.\n","- Como los recursos están la nube, no hay que preocuparse por los recursos de hardware\n","- Trabajo en equipo, más sencillo el trabajo colaborativo. Varias personas pueden trabajar sobre un mismo notebook.\n","\n","\n","Desventajas:\n","- No se guardan las configuraciones de Spark luego de un tiempo\n","> No obstante el notebook permanece intacto. Se puede volver a ejecutar las líneas de código para tener la configuración nuevamente.\n","- Escalabilidad, como el servicio es gratuito, los recursos son limitados.\n","> Para llevarlo a ambientes productivos, necesitamos una infraestructura capaz de brindarnos estas especificaciones."]},{"cell_type":"markdown","metadata":{"id":"CqjAFIHMJoQc"},"source":["## Instalaciones Necesarias para trabajar con Spark en Colab"]},{"cell_type":"markdown","metadata":{"id":"LccNQX8WMBtl"},"source":["### `Descarga e instalación de Apache Spark en Colab`\n","Se explica celda por celda las instalaciones necesarias. Para fines prácticos, utilizar la celda de abajo que instala todo junto."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPNdekO7KHTp"},"outputs":[],"source":["# Instalar SDK Java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peqw7BfRKjHE"},"outputs":[],"source":["# Descargar Spark 3.2.4\n","!wget -q https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIsOwRkJKjEi"},"outputs":[],"source":["# Descomprimir el archivo descargado de Spark\n","!tar xf spark-3.2.4-bin-hadoop3.2.tgz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUtXLbwuKjBH"},"outputs":[],"source":["# Establecer las variables de entorno\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.4-bin-hadoop3.2\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMM5SJEPKi_X"},"outputs":[],"source":["# Instalar la librería findspark\n","!pip install -q findspark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36078,"status":"ok","timestamp":1708225550840,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"},"user_tz":180},"id":"51AZCLcVKi9x","outputId":"f9126ed1-b460-4e91-ea89-35223d84a511"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# Instalar pyspark\n","!pip install -q pyspark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AMEAXrbKi8o"},"outputs":[],"source":["### verificar la instalación ###\n","import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6201,"status":"ok","timestamp":1708226374480,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"},"user_tz":180},"id":"QivCkbKRKi6g","outputId":"09e383c5-012f-421b-bb97-d329a12167b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+\n","| Hola|\n","+-----+\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","+-----+\n","\n"]}],"source":["# Probando la sesión de Spark\n","df = spark.createDataFrame([{\"Hola\": \"Mundo\"} for x in range(10)])\n","# df.show(10, False)\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"U_xdI5-TOhbo"},"source":["### `Descarga e instalación de Apache Spark en una sola celda (Utilizar esta opción)`\n","Para fines prácticos, toda la instalación está en una celda, así luego de ejecutarse ya se puede trabajar con Spark."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129065,"status":"ok","timestamp":1723487353125,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"},"user_tz":180},"id":"wEvprYN0Ot1l","outputId":"5cb64e13-1347-4f2b-d4c6-c7e3c9420b35"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","+-----+\n","| Hola|\n","+-----+\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","|Mundo|\n","+-----+\n","\n"]}],"source":["# Instalar SDK Java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Spark 3.2.4\n","!wget -q https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz\n","\n","# Descomprimir el archivo descargado de Spark\n","!tar xf spark-3.2.4-bin-hadoop3.2.tgz\n","\n","# Establecer las variables de entorno\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.4-bin-hadoop3.2\"\n","\n","# Instalar la librería findspark\n","!pip install -q findspark\n","\n","# Instalar pyspark\n","!pip install -q pyspark\n","\n","### verificar la instalación ###\n","import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","\n","# Probando la sesión de Spark\n","df = spark.createDataFrame([{\"Hola\": \"Mundo\"} for x in range(10)])\n","# df.show(10, False)\n","df.show()"]},{"cell_type":"markdown","source":["## `Importante: Carga de archivos en Google Colab`\n","\n","Dos formas de cargar los archivos para resolver los ejercicios:\n","\n","1. **Montando el drive para acceder a los contenidos** de la unidad.\n","\n","  Utilizar esta opción si los datos para los ejercicios se cargan en una carpeta del drive y se quiere acceder a ella.\n","\n","2. **Utilizando el cuadro de archivos**, donde se carga el archivo que se quiere trabajar. Se guarda temporalmente.\n","> Esta es la forma que voy a estar utizando"],"metadata":{"id":"Jz_8wAjF-CZL"}},{"cell_type":"code","source":["# Levantar una sesión de Spark\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName('Cap2').master('local(*)').getOrCreate()\n","spark"],"metadata":{"id":"f-J8eWCz-Fei"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. Utilizando el montado al drive y yendo hacia la carpeta donde se encuentra el archivo."],"metadata":{"id":"QXy8YNeO-Jau"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"pmN9OdbH-KM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rdd_texto = sc.wholeTextFiles('/content/drive/MyDrive/Spark/data-ej-PySpark-RDD/el_valor_del_big_data.txt')\n","rdd_texto.collect()"],"metadata":{"id":"o79J5JOS-QN2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Utilizando el cuadro de archivos, donde se carga el archivo que se quiere trabajar. Se guarda temporalmente.\n","\n","Esta es la que voy a estar utizando a lo largo de todos los notebooks.\n"],"metadata":{"id":"NAHsX9e2-Kxs"}},{"cell_type":"code","source":["rdd_texto = sc.wholeTextFiles('./el_valor_del_big_data.txt')\n","rdd_texto.collect()"],"metadata":{"id":"Lr2_B-R0-LeE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q5eOVSiKAhWl"},"source":["## Spark UI en Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1IQB2NmAleg","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1722544439913,"user_tz":180,"elapsed":49948,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"1dddf7c5-10f6-4930-bafe-4ccec733b3be"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, text, element) => {\n","    if (!google.colab.kernel.accessAllowed) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port);\n","    const anchor = document.createElement('a');\n","    anchor.href = new URL(path, url).toString();\n","    anchor.target = '_blank';\n","    anchor.setAttribute('data-href', url + path);\n","    anchor.textContent = text;\n","    element.appendChild(anchor);\n","  })(4050, \"/jobs/index.html\", \"https://localhost:4050/jobs/index.html\", window.element)"]},"metadata":{}}],"source":["# Instalar SDK java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Spark\n","!wget -q https://archive.apache.org/dist/spark/spark-3.3.4/spark-3.3.4-bin-hadoop3.tgz\n","\n","# Descomprimir la version de Spark\n","!tar xf spark-3.3.4-bin-hadoop3.tgz\n","\n","# Establecer las variables de entorno\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.4-bin-hadoop3\"\n","\n","# Descargar findspark\n","!pip install -q findspark\n","\n","# Crear la sesión de Spark\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = (\n","    SparkSession.builder\n","    .config('spark.ui.port', '4050')\n","    .getOrCreate()\n",")\n","\n","from google.colab import output\n","output.serve_kernel_port_as_window(4050, path='/jobs/index.html')\n","from pyspark.sql.functions import col\n","\n","spark.range(10000).toDF(\"id\").filter(col('id') / 2 == 0).write.mode('overwrite').parquet('/output')"]},{"cell_type":"markdown","metadata":{"id":"4xTFXrXNSG_b"},"source":["## Spark SQL Básico"]},{"cell_type":"markdown","source":["- En Spark 1.6 se introdujo una nueva abstracción de programación llamada API Estructurada. Esta es la forma preferida para realizar el procesamiento de datos de la mayoría de los casos de uso.\n","\n","- En esta nueva forma de hacer el procesamiento de datos, los datos deben organizarse en un formato estructurado y la lógica de cálculo de datos debe seguir una determinada estructura.\n","\n","- Con estas dos piezas de información, Spark puede realizar optimizaciones para acelerar las aplicaciones de procesamiento de datos.\n","\n","- Dataframe -> Gran Volumen de datos -> Schema -> formato determinado\n","\n","- Spark SQL <----> formato determinado\n","\n","- Lectura <----> Escritura (Spark puede utilizarse como una herramienta de conversión de formato de datos)"],"metadata":{"id":"HWwfKcsnqHlD"}},{"cell_type":"markdown","metadata":{"id":"AONlSDOoxVza"},"source":["### Dataframes: Parte I\n","Creando dataframes, a partir de un RDD."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UA7iE-ksSL38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722732225267,"user_tz":180,"elapsed":897,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"8504877f-aed9-4821-d118-32277c3bfa3f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 0),\n"," (1, 1),\n"," (2, 4),\n"," (3, 9),\n"," (4, 16),\n"," (5, 25),\n"," (6, 36),\n"," (7, 49),\n"," (8, 64),\n"," (9, 81)]"]},"metadata":{},"execution_count":3}],"source":["# Levantar una sesión de Spark\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext\n","\n","rdd = sc.parallelize([item for item in range(10)]).map(lambda x: (x, x ** 2))\n","rdd.collect()"]},{"cell_type":"markdown","source":["#### 1. Creando un dataframe a partir de un RDD"],"metadata":{"id":"sKQuuTM3s1ru"}},{"cell_type":"code","source":["df = rdd.toDF(['numero', 'cudrado'])\n","df.printSchema()\n","df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78PV9BZFs4zA","executionInfo":{"status":"ok","timestamp":1722732230648,"user_tz":180,"elapsed":2122,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"d4bad2c8-5f6a-4857-d917-8ca2cb65cbe2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- numero: long (nullable = true)\n"," |-- cudrado: long (nullable = true)\n","\n","+------+-------+\n","|numero|cudrado|\n","+------+-------+\n","|     0|      0|\n","|     1|      1|\n","|     2|      4|\n","|     3|      9|\n","|     4|     16|\n","|     5|     25|\n","|     6|     36|\n","|     7|     49|\n","|     8|     64|\n","|     9|     81|\n","+------+-------+\n","\n"]}]},{"cell_type":"markdown","source":["#### Ver el Schema"],"metadata":{"id":"8ipK8jKetQ7l"}},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enBHgNMDtTtF","executionInfo":{"status":"ok","timestamp":1722732234398,"user_tz":180,"elapsed":321,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"bde3f684-190a-4ed3-83c0-fcd514a99b29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- numero: long (nullable = true)\n"," |-- cudrado: long (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["#### Ver una cierta cantidad de registros (por defecto se muestran 10)"],"metadata":{"id":"LQoQWzKwtoZG"}},{"cell_type":"code","source":["df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E79Ej3L7tveK","executionInfo":{"status":"ok","timestamp":1722732237653,"user_tz":180,"elapsed":846,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"b32c8f3b-6299-4ac3-9c94-a73a83eac1af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+-------+\n","|numero|cudrado|\n","+------+-------+\n","|     0|      0|\n","|     1|      1|\n","|     2|      4|\n","|     3|      9|\n","|     4|     16|\n","|     5|     25|\n","|     6|     36|\n","|     7|     49|\n","|     8|     64|\n","|     9|     81|\n","+------+-------+\n","\n"]}]},{"cell_type":"markdown","source":["#### 2. Creando un dataframe a partir de un RDD  con Schema"],"metadata":{"id":"1p1IW6xgs_9X"}},{"cell_type":"code","source":["# Crear un DataFrame a partir de un RDD con schema\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n","\n","rdd1 = sc.parallelize([(1, 'Jose', 35.5), (2, 'Teresa', 54.3), (3, 'Katia', 12.7)])"],"metadata":{"id":"zEQ_ckLD2Vbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Primera vía\n","# nombre de la columna, tipo de dato, admite nulos o no\n","esquema1 = StructType(\n","    [\n","     StructField('id', IntegerType(), True),\n","     StructField('nombre', StringType(), True),\n","     StructField('saldo', DoubleType(), True)\n","    ]\n",")\n","\n","df1 = spark.createDataFrame(rdd1, schema=esquema1)\n","df1.printSchema()\n","df1.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CT69EN-ssim","executionInfo":{"status":"ok","timestamp":1722732404937,"user_tz":180,"elapsed":805,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"ea5bd93b-2b19-4632-c288-5b9e5e588738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- id: integer (nullable = true)\n"," |-- nombre: string (nullable = true)\n"," |-- saldo: double (nullable = true)\n","\n","+---+------+-----+\n","| id|nombre|saldo|\n","+---+------+-----+\n","|  1|  Jose| 35.5|\n","|  2|Teresa| 54.3|\n","|  3| Katia| 12.7|\n","+---+------+-----+\n","\n"]}]},{"cell_type":"code","source":["# Segunda vía\n","# nombre de la columna, tipo de dato, admite nulos o no\n","esquema2 = \"`id` INT, `nombre` STRING, `saldo` DOUBLE\"\n","\n","df2 = spark.createDataFrame(rdd1, schema=esquema2)\n","df2.printSchema()\n","df2.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bill50HY2hjm","executionInfo":{"status":"ok","timestamp":1722732416177,"user_tz":180,"elapsed":1249,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"e5b0c859-b8bf-4633-c2f4-e1a6e68d6e5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- id: integer (nullable = true)\n"," |-- nombre: string (nullable = true)\n"," |-- saldo: double (nullable = true)\n","\n","+---+------+-----+\n","| id|nombre|saldo|\n","+---+------+-----+\n","|  1|  Jose| 35.5|\n","|  2|Teresa| 54.3|\n","|  3| Katia| 12.7|\n","+---+------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["#### 3. Creando un dataframe a partir de un rango de números"],"metadata":{"id":"kz_ugXS92sz0"}},{"cell_type":"code","source":["# Crear un DataFrame a partir de un rango de números\n","spark.range(5).toDF('id').show()\n","spark.range(3, 15).toDF('id').show()\n","spark.range(0, 20, 2).toDF('id').show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kc2CbCkK2iKB","executionInfo":{"status":"ok","timestamp":1722732471116,"user_tz":180,"elapsed":1733,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"ecbd182d-d343-4277-f4fc-a59fb12813ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+\n","| id|\n","+---+\n","|  0|\n","|  1|\n","|  2|\n","|  3|\n","|  4|\n","+---+\n","\n","+---+\n","| id|\n","+---+\n","|  3|\n","|  4|\n","|  5|\n","|  6|\n","|  7|\n","|  8|\n","|  9|\n","| 10|\n","| 11|\n","| 12|\n","| 13|\n","| 14|\n","+---+\n","\n","+---+\n","| id|\n","+---+\n","|  0|\n","|  2|\n","|  4|\n","|  6|\n","|  8|\n","| 10|\n","| 12|\n","| 14|\n","| 16|\n","| 18|\n","+---+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"3HYKvYDfxkkF"},"source":["### Dataframes: Parte II\n","Creando dataframes, a partir de una fuente de datos."]},{"cell_type":"markdown","source":["#### Spark SQL tiene dos clases principales para leer y escribir datos:"],"metadata":{"id":"OMvFeqRfvYKZ"}},{"cell_type":"markdown","source":["- DataFrameReader\n","- DataFrameWriter\n","\n","Una instancia de la clase DataFrameReader está disponible como read en la sesión de Spark.\n","\n","Spark.read\n","\n","El patrón común para interactuar con DataFrameReader es:\n","\n","Spark.read.format(...).option('key', 'value').schema(...).load()\n","\n","format no es opcional (hay que indicar si es cvs, parquet, json, etc), pero option y schema si lo son ya que option tiene opciones predeterminadas y schema por defecto infiere el tipo de dato."],"metadata":{"id":"J7U6jlMSy5te"}},{"cell_type":"markdown","source":["#### Alternativas para leer datos:"],"metadata":{"id":"aMowH838zAg-"}},{"cell_type":"markdown","source":["- spark.read.csv(\"path\")\n","- spark.read.format(\"csv\")\n","\n","- spark.read.text(\"path\")\n","- spark.read.format(\"text\")\n","\n","- spark.read.json(\"path\")\n","- spark.read.format(\"json\")\n","\n","- spark.read.parquet(\"path\")\n","- spark.read.format(\"parquet\")\n","\n","- spark.read.jdbc(\"path\")\n","- spark.read.format(\"jdbc\")\n","\n","- spark.read.orc(\"path\")\n","- spark.read.format(\"orc\")\n"],"metadata":{"id":"zfHhYJrAyxH2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vVtpG6-GSMYe"},"outputs":[],"source":["# Creando DataFrames\n","\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext\n","\n","rdd = sc.parallelize([item for item in range(10)]).map(lambda x: (x, x ** 2))\n","\n","rdd.collect()\n","\n","df = rdd.toDF(['numero', 'cudrado'])\n","\n","df.printSchema()\n","\n","df.show()\n","\n","# Crear un DataFrame a partir de un RDD con schema\n","\n","rdd1 = sc.parallelize([(1, 'Jose', 35.5), (2, 'Teresa', 54.3), (3, 'Katia', 12.7)])\n","\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n","\n","# Primera vía\n","\n","esquema1 = StructType(\n","    [\n","     StructField('id', IntegerType(), True),\n","     StructField('nombre', StringType(), True),\n","     StructField('saldo', DoubleType(), True)\n","    ]\n",")\n","\n","# Segunda vía\n","\n","esquema2 = \"`id` INT, `nombre` STRING, `saldo` DOUBLE\"\n","\n","df1 = spark.createDataFrame(rdd1, schema=esquema1)\n","\n","df1.printSchema()\n","\n","df1.show()\n","\n","df2 = spark.createDataFrame(rdd1, schema=esquema2)\n","\n","df2.printSchema()\n","\n","df2.show()\n","\n","# Crear un DataFrame a partir de un rango de números\n","\n","spark.range(5).toDF('id').show()\n","\n","spark.range(3, 15).toDF('id').show()\n","\n","spark.range(0, 20, 2).toDF('id').show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NtTo8TzaIfoU"},"source":["#### Crear un dataframe mediante la lectura de un archivo de texto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKZHSUcKSMWp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723490325463,"user_tz":180,"elapsed":2021,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"d49da957-0f92-4553-b6af-bb005d1b5b2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+\n","|               value|\n","+--------------------+\n","|Estamos en el cur...|\n","|En este capítulo ...|\n","|En esta sección e...|\n","|y en este ejemplo...|\n","+--------------------+\n","\n","+-----------------------------------------------------------------------+\n","|value                                                                  |\n","+-----------------------------------------------------------------------+\n","|Estamos en el curso de pyspark                                         |\n","|En este capítulo estamos estudiando el API SQL de Saprk                |\n","|En esta sección estamos creado dataframes a partir de fuentes de datos,|\n","|y en este ejemplo creamos un dataframe a partir de un texto plano      |\n","+-----------------------------------------------------------------------+\n","\n"]}],"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","# Crear un DataFrame mediante la lectura de un archivo de texto\n","df = spark.read.text('dataTXT.txt')\n","df.show()\n","df.show(truncate=False)"]},{"cell_type":"markdown","source":["#### Crear un DataFrame mediante la lectura de un archivo csv"],"metadata":{"id":"pEkCgGOW1WF3"}},{"cell_type":"code","source":["# Crear un DataFrame mediante la lectura de un archivo csv\n","df1 = spark.read.csv('dataCSV.csv')\n","df1.show()"],"metadata":{"id":"juvP0Wko1NZ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723490374849,"user_tz":180,"elapsed":1933,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"255b3106-0f15-4f44-ac62-086ecf8b6fc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+--------------------+--------------------+\n","|        _c0|          _c1|                 _c2|                 _c3|        _c4|                 _c5|                 _c6|    _c7|   _c8|     _c9|         _c10|                _c11|             _c12|            _c13|                _c14|                _c15|\n","+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+--------------------+--------------------+\n","|   video_id|trending_date|               title|       channel_title|category_id|        publish_time|                tags|  views| likes|dislikes|comment_count|      thumbnail_link|comments_disabled|ratings_disabled|video_error_or_re...|         description|\n","|2kyS6SvSYSE|     17.14.11|WE WANT TO TALK A...|        CaseyNeistat|         22|2017-11-13T17:13:...|     SHANtell martin| 748374| 57527|    2966|        15954|https://i.ytimg.c...|            False|           False|               False|SHANTELL'S CHANNE...|\n","|1ZAPwfrtAFY|     17.14.11|The Trump Preside...|     LastWeekTonight|         24|2017-11-13T07:30:...|\"last week tonigh...|2418783| 97185|    6146|        12703|https://i.ytimg.c...|            False|           False|               False|One year after th...|\n","|5qpjK5DgCt4|     17.14.11|Racist Superman |...|        Rudy Mancuso|         23|2017-11-12T19:05:...|\"racist superman\"...|3191434|146033|    5339|         8181|https://i.ytimg.c...|            False|           False|               False|WATCH MY PREVIOUS...|\n","|puqaWrEC7tY|     17.14.11|Nickelback Lyrics...|Good Mythical Mor...|         24|2017-11-13T11:00:...|\"rhett and link\"|...| 343168| 10172|     666|         2146|https://i.ytimg.c...|            False|           False|               False|Today we find out...|\n","|d380meD0W0M|     17.14.11|I Dare You: GOING...|            nigahiga|         24|2017-11-12T18:01:...|\"ryan\"|\"higa\"|\"hi...|2095731|132235|    1989|        17518|https://i.ytimg.c...|            False|           False|               False|I know it's been ...|\n","|gHZ1Qz0KiKM|     17.14.11|2 Weeks with iPho...|            iJustine|         28|2017-11-13T19:07:...|\"ijustine\"|\"week ...| 119180|  9763|     511|         1434|https://i.ytimg.c...|            False|           False|               False|Using the iPhone ...|\n","|39idVpFF7NQ|     17.14.11|Roy Moore & Jeff ...| Saturday Night Live|         24|2017-11-12T05:37:...|\"SNL\"|\"Saturday N...|2103417| 15993|    2445|         1970|https://i.ytimg.c...|            False|           False|               False|Embattled Alabama...|\n","|nc99ccSXST0|     17.14.11|5 Ice Cream Gadge...|  CrazyRussianHacker|         28|2017-11-12T21:50:...|\"5 Ice Cream Gadg...| 817732| 23663|     778|         3432|https://i.ytimg.c...|            False|           False|               False|Ice Cream Pint Co...|\n","|jr9QtXwC9vc|     17.14.11|The Greatest Show...|    20th Century Fox|          1|2017-11-13T14:00:...|\"Trailer\"|\"Hugh J...| 826059|  3543|     119|          340|https://i.ytimg.c...|            False|           False|               False|Inspired by the i...|\n","|TUmyygCMMGA|     17.14.11|Why the rise of t...|                 Vox|         25|2017-11-13T13:45:...|\"vox.com\"|\"vox\"|\"...| 256426| 12654|    1363|         2368|https://i.ytimg.c...|            False|           False|               False|For now, at least...|\n","|9wRQljFNDW8|     17.14.11|Dion Lewis' 103-Y...|                 NFL|         17|2017-11-13T02:05:...|\"NFL\"|\"Football\"|...|  81377|   655|      25|          177|https://i.ytimg.c...|            False|           False|               False|New England Patri...|\n","|VifQlJit6A0|     17.14.11|(SPOILERS) 'Shiva...|                 amc|         24|2017-11-13T03:00:...|\"The Walking Dead...| 104578|  1576|     303|         1279|https://i.ytimg.c...|            False|           False|               False|Shiva arrives jus...|\n","|5E4ZBSInqUU|     17.14.11|Marshmello - Bloc...|          marshmello|         10|2017-11-13T17:00:...|\"marshmello\"|\"blo...| 687582|114188|    1333|         8371|https://i.ytimg.c...|            False|           False|               False|WATCH SILENCE MUS...|\n","|GgVmn66oK_A|     17.14.11|Which Countries A...|       NowThis World|         25|2017-11-12T14:00:...|\"nowthis\"|\"nowthi...| 544770|  7848|    1171|         3981|https://i.ytimg.c...|            False|           False|               False|The world at larg...|\n","|TaTleo4cOs8|     17.14.11|SHOPPING FOR NEW ...|     The king of DIY|         15|2017-11-12T18:30:...|\"shopping for new...| 207532|  7473|     246|         2120|https://i.ytimg.c...|            False|           False|               False|Today we go shopp...|\n","|kgaO45SyaO4|     17.14.11|    The New SpotMini|      BostonDynamics|         28|2017-11-13T20:09:...|\"Robots\"|\"Boston ...|  75752|  9419|      52|         1230|https://i.ytimg.c...|            False|           False|               False|For more informat...|\n","|ZAQs-ctOqXQ|     17.14.11|One Change That W...|             Cracked|         23|2017-11-12T17:00:...|\"pacific rim\"|\"pa...| 295639|  8011|     638|         1256|https://i.ytimg.c...|            False|           False|               False|Pacific Rim was s...|\n","|YVfyYrEmzgM|     17.14.11|How does your bod...|              TED-Ed|         27|2017-11-13T16:00:...|\"TED\"|\"TED-Ed\"|\"T...|  78044|  5398|      53|          385|https://i.ytimg.c...|            False|           False|               False|Check out our Pat...|\n","|eNSN6qet1kE|     17.14.11|HomeMade Electric...|         PeterSripol|         28|2017-11-13T15:30:...|\"ultralight\"|\"air...|  97007| 11963|      36|         2211|https://i.ytimg.c...|            False|           False|               False|aaaannnd now to f...|\n","+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["df1 = spark.read.option('header', 'true').csv('dataCSV.csv')\n","df1.show()"],"metadata":{"id":"UyqkMnsZ1dI0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723490382240,"user_tz":180,"elapsed":1237,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"3b1f25fc-c434-4cbe-d4e9-7afacd399869"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n","|   video_id|trending_date|               title|       channel_title|category_id|        publish_time|                tags|  views| likes|dislikes|comment_count|      thumbnail_link|comments_disabled|ratings_disabled|video_error_or_removed|         description|\n","+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n","|2kyS6SvSYSE|     17.14.11|WE WANT TO TALK A...|        CaseyNeistat|         22|2017-11-13T17:13:...|     SHANtell martin| 748374| 57527|    2966|        15954|https://i.ytimg.c...|            False|           False|                 False|SHANTELL'S CHANNE...|\n","|1ZAPwfrtAFY|     17.14.11|The Trump Preside...|     LastWeekTonight|         24|2017-11-13T07:30:...|\"last week tonigh...|2418783| 97185|    6146|        12703|https://i.ytimg.c...|            False|           False|                 False|One year after th...|\n","|5qpjK5DgCt4|     17.14.11|Racist Superman |...|        Rudy Mancuso|         23|2017-11-12T19:05:...|\"racist superman\"...|3191434|146033|    5339|         8181|https://i.ytimg.c...|            False|           False|                 False|WATCH MY PREVIOUS...|\n","|puqaWrEC7tY|     17.14.11|Nickelback Lyrics...|Good Mythical Mor...|         24|2017-11-13T11:00:...|\"rhett and link\"|...| 343168| 10172|     666|         2146|https://i.ytimg.c...|            False|           False|                 False|Today we find out...|\n","|d380meD0W0M|     17.14.11|I Dare You: GOING...|            nigahiga|         24|2017-11-12T18:01:...|\"ryan\"|\"higa\"|\"hi...|2095731|132235|    1989|        17518|https://i.ytimg.c...|            False|           False|                 False|I know it's been ...|\n","|gHZ1Qz0KiKM|     17.14.11|2 Weeks with iPho...|            iJustine|         28|2017-11-13T19:07:...|\"ijustine\"|\"week ...| 119180|  9763|     511|         1434|https://i.ytimg.c...|            False|           False|                 False|Using the iPhone ...|\n","|39idVpFF7NQ|     17.14.11|Roy Moore & Jeff ...| Saturday Night Live|         24|2017-11-12T05:37:...|\"SNL\"|\"Saturday N...|2103417| 15993|    2445|         1970|https://i.ytimg.c...|            False|           False|                 False|Embattled Alabama...|\n","|nc99ccSXST0|     17.14.11|5 Ice Cream Gadge...|  CrazyRussianHacker|         28|2017-11-12T21:50:...|\"5 Ice Cream Gadg...| 817732| 23663|     778|         3432|https://i.ytimg.c...|            False|           False|                 False|Ice Cream Pint Co...|\n","|jr9QtXwC9vc|     17.14.11|The Greatest Show...|    20th Century Fox|          1|2017-11-13T14:00:...|\"Trailer\"|\"Hugh J...| 826059|  3543|     119|          340|https://i.ytimg.c...|            False|           False|                 False|Inspired by the i...|\n","|TUmyygCMMGA|     17.14.11|Why the rise of t...|                 Vox|         25|2017-11-13T13:45:...|\"vox.com\"|\"vox\"|\"...| 256426| 12654|    1363|         2368|https://i.ytimg.c...|            False|           False|                 False|For now, at least...|\n","|9wRQljFNDW8|     17.14.11|Dion Lewis' 103-Y...|                 NFL|         17|2017-11-13T02:05:...|\"NFL\"|\"Football\"|...|  81377|   655|      25|          177|https://i.ytimg.c...|            False|           False|                 False|New England Patri...|\n","|VifQlJit6A0|     17.14.11|(SPOILERS) 'Shiva...|                 amc|         24|2017-11-13T03:00:...|\"The Walking Dead...| 104578|  1576|     303|         1279|https://i.ytimg.c...|            False|           False|                 False|Shiva arrives jus...|\n","|5E4ZBSInqUU|     17.14.11|Marshmello - Bloc...|          marshmello|         10|2017-11-13T17:00:...|\"marshmello\"|\"blo...| 687582|114188|    1333|         8371|https://i.ytimg.c...|            False|           False|                 False|WATCH SILENCE MUS...|\n","|GgVmn66oK_A|     17.14.11|Which Countries A...|       NowThis World|         25|2017-11-12T14:00:...|\"nowthis\"|\"nowthi...| 544770|  7848|    1171|         3981|https://i.ytimg.c...|            False|           False|                 False|The world at larg...|\n","|TaTleo4cOs8|     17.14.11|SHOPPING FOR NEW ...|     The king of DIY|         15|2017-11-12T18:30:...|\"shopping for new...| 207532|  7473|     246|         2120|https://i.ytimg.c...|            False|           False|                 False|Today we go shopp...|\n","|kgaO45SyaO4|     17.14.11|    The New SpotMini|      BostonDynamics|         28|2017-11-13T20:09:...|\"Robots\"|\"Boston ...|  75752|  9419|      52|         1230|https://i.ytimg.c...|            False|           False|                 False|For more informat...|\n","|ZAQs-ctOqXQ|     17.14.11|One Change That W...|             Cracked|         23|2017-11-12T17:00:...|\"pacific rim\"|\"pa...| 295639|  8011|     638|         1256|https://i.ytimg.c...|            False|           False|                 False|Pacific Rim was s...|\n","|YVfyYrEmzgM|     17.14.11|How does your bod...|              TED-Ed|         27|2017-11-13T16:00:...|\"TED\"|\"TED-Ed\"|\"T...|  78044|  5398|      53|          385|https://i.ytimg.c...|            False|           False|                 False|Check out our Pat...|\n","|eNSN6qet1kE|     17.14.11|HomeMade Electric...|         PeterSripol|         28|2017-11-13T15:30:...|\"ultralight\"|\"air...|  97007| 11963|      36|         2211|https://i.ytimg.c...|            False|           False|                 False|aaaannnd now to f...|\n","|B5HORANmzHw|     17.14.11|Founding An Inbre...|             SciShow|         27|2017-11-12T22:00:...|\"SciShow\"|\"scienc...| 223871|  8421|     191|         1214|https://i.ytimg.c...|            False|           False|                 False|Thanks to 23AndMe...|\n","+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["#### Leer un archivo de texto con un delimitador diferente"],"metadata":{"id":"fQFIkacK1q-p"}},{"cell_type":"code","source":["# Leer un archivo de texto con un delimitador diferente\n","df2 = spark.read.option('header', 'true').option('delimiter', '|').csv('dataTab.txt')\n","df2.show()"],"metadata":{"id":"e3PILr-C1pox","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723490395325,"user_tz":180,"elapsed":1125,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"900abd9c-2607-4bc6-a9d1-de960567e4e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+----+----------+-----+\n","|pais|edad|     fecha|color|\n","+----+----+----------+-----+\n","|  MX|  23|2021-02-21| rojo|\n","|  CA|  56|2021-06-10| azul|\n","|  US|  32|2020-06-02|verde|\n","+----+----+----------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["#### Crear un DataFrame a partir de un json proporcionando un schema"],"metadata":{"id":"SGDsLACt11Cy"}},{"cell_type":"code","source":["# Crear un DataFrame a partir de un json proporcionando un schema\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n","\n","json_schema =  StructType(\n","    [\n","     StructField('color', StringType(), True),\n","     StructField('edad', IntegerType(), True),\n","     StructField('fecha', DateType(), True),\n","     StructField('pais', StringType(), True)\n","    ]\n",")\n","\n","df4 = spark.read.schema(json_schema).json('dataJSON.json')\n","df4.show()\n","df4.printSchema()"],"metadata":{"id":"b2srWVcw10hW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723490404621,"user_tz":180,"elapsed":796,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"9642a861-fe8e-43e4-8c6e-8b3559d270f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+----+----------+----+\n","|color|edad|     fecha|pais|\n","+-----+----+----------+----+\n","| rojo|null|2021-02-21|  MX|\n","| azul|null|2021-06-10|  CA|\n","|verde|null|2020-06-02|  US|\n","+-----+----+----------+----+\n","\n","root\n"," |-- color: string (nullable = true)\n"," |-- edad: integer (nullable = true)\n"," |-- fecha: date (nullable = true)\n"," |-- pais: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["#### Crear un DataFrame a partir de un archivo parquet"],"metadata":{"id":"PM5r13Xy2Jg2"}},{"cell_type":"code","source":["\n","# Crear un DataFrame a partir de un archivo parquet\n","df5 = spark.read.parquet('dataPARQUET.parquet')\n","df5.show()\n","\n","# Otra alternativa para leer desde una fuente de datos parquet en este caso\n","df6 = spark.read.format('parquet').load('dataPARQUET.parquet')\n","df6.printSchema()"],"metadata":{"id":"pnmLVWrY2I3l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723490668742,"user_tz":180,"elapsed":2469,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"0c28dee8-9caa-4f10-95db-382a29d24161"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n","|   video_id|trending_date|               title|       channel_title|category_id|        publish_time|                tags|  views| likes|dislikes|comment_count|      thumbnail_link|comments_disabled|ratings_disabled|video_error_or_removed|         description|\n","+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n","|2kyS6SvSYSE|     17.14.11|WE WANT TO TALK A...|        CaseyNeistat|         22|2017-11-13T17:13:...|     SHANtell martin| 748374| 57527|    2966|        15954|https://i.ytimg.c...|            False|           False|                 False|SHANTELL'S CHANNE...|\n","|1ZAPwfrtAFY|     17.14.11|The Trump Preside...|     LastWeekTonight|         24|2017-11-13T07:30:...|\"last week tonigh...|2418783| 97185|    6146|        12703|https://i.ytimg.c...|            False|           False|                 False|One year after th...|\n","|5qpjK5DgCt4|     17.14.11|Racist Superman |...|        Rudy Mancuso|         23|2017-11-12T19:05:...|\"racist superman\"...|3191434|146033|    5339|         8181|https://i.ytimg.c...|            False|           False|                 False|WATCH MY PREVIOUS...|\n","|puqaWrEC7tY|     17.14.11|Nickelback Lyrics...|Good Mythical Mor...|         24|2017-11-13T11:00:...|\"rhett and link\"|...| 343168| 10172|     666|         2146|https://i.ytimg.c...|            False|           False|                 False|Today we find out...|\n","|d380meD0W0M|     17.14.11|I Dare You: GOING...|            nigahiga|         24|2017-11-12T18:01:...|\"ryan\"|\"higa\"|\"hi...|2095731|132235|    1989|        17518|https://i.ytimg.c...|            False|           False|                 False|I know it's been ...|\n","|gHZ1Qz0KiKM|     17.14.11|2 Weeks with iPho...|            iJustine|         28|2017-11-13T19:07:...|\"ijustine\"|\"week ...| 119180|  9763|     511|         1434|https://i.ytimg.c...|            False|           False|                 False|Using the iPhone ...|\n","|39idVpFF7NQ|     17.14.11|Roy Moore & Jeff ...| Saturday Night Live|         24|2017-11-12T05:37:...|\"SNL\"|\"Saturday N...|2103417| 15993|    2445|         1970|https://i.ytimg.c...|            False|           False|                 False|Embattled Alabama...|\n","|nc99ccSXST0|     17.14.11|5 Ice Cream Gadge...|  CrazyRussianHacker|         28|2017-11-12T21:50:...|\"5 Ice Cream Gadg...| 817732| 23663|     778|         3432|https://i.ytimg.c...|            False|           False|                 False|Ice Cream Pint Co...|\n","|jr9QtXwC9vc|     17.14.11|The Greatest Show...|    20th Century Fox|          1|2017-11-13T14:00:...|\"Trailer\"|\"Hugh J...| 826059|  3543|     119|          340|https://i.ytimg.c...|            False|           False|                 False|Inspired by the i...|\n","|TUmyygCMMGA|     17.14.11|Why the rise of t...|                 Vox|         25|2017-11-13T13:45:...|\"vox.com\"|\"vox\"|\"...| 256426| 12654|    1363|         2368|https://i.ytimg.c...|            False|           False|                 False|For now, at least...|\n","|9wRQljFNDW8|     17.14.11|Dion Lewis' 103-Y...|                 NFL|         17|2017-11-13T02:05:...|\"NFL\"|\"Football\"|...|  81377|   655|      25|          177|https://i.ytimg.c...|            False|           False|                 False|New England Patri...|\n","|VifQlJit6A0|     17.14.11|(SPOILERS) 'Shiva...|                 amc|         24|2017-11-13T03:00:...|\"The Walking Dead...| 104578|  1576|     303|         1279|https://i.ytimg.c...|            False|           False|                 False|Shiva arrives jus...|\n","|5E4ZBSInqUU|     17.14.11|Marshmello - Bloc...|          marshmello|         10|2017-11-13T17:00:...|\"marshmello\"|\"blo...| 687582|114188|    1333|         8371|https://i.ytimg.c...|            False|           False|                 False|WATCH SILENCE MUS...|\n","|GgVmn66oK_A|     17.14.11|Which Countries A...|       NowThis World|         25|2017-11-12T14:00:...|\"nowthis\"|\"nowthi...| 544770|  7848|    1171|         3981|https://i.ytimg.c...|            False|           False|                 False|The world at larg...|\n","|TaTleo4cOs8|     17.14.11|SHOPPING FOR NEW ...|     The king of DIY|         15|2017-11-12T18:30:...|\"shopping for new...| 207532|  7473|     246|         2120|https://i.ytimg.c...|            False|           False|                 False|Today we go shopp...|\n","|kgaO45SyaO4|     17.14.11|    The New SpotMini|      BostonDynamics|         28|2017-11-13T20:09:...|\"Robots\"|\"Boston ...|  75752|  9419|      52|         1230|https://i.ytimg.c...|            False|           False|                 False|For more informat...|\n","|ZAQs-ctOqXQ|     17.14.11|One Change That W...|             Cracked|         23|2017-11-12T17:00:...|\"pacific rim\"|\"pa...| 295639|  8011|     638|         1256|https://i.ytimg.c...|            False|           False|                 False|Pacific Rim was s...|\n","|YVfyYrEmzgM|     17.14.11|How does your bod...|              TED-Ed|         27|2017-11-13T16:00:...|\"TED\"|\"TED-Ed\"|\"T...|  78044|  5398|      53|          385|https://i.ytimg.c...|            False|           False|                 False|Check out our Pat...|\n","|eNSN6qet1kE|     17.14.11|HomeMade Electric...|         PeterSripol|         28|2017-11-13T15:30:...|\"ultralight\"|\"air...|  97007| 11963|      36|         2211|https://i.ytimg.c...|            False|           False|                 False|aaaannnd now to f...|\n","|B5HORANmzHw|     17.14.11|Founding An Inbre...|             SciShow|         27|2017-11-12T22:00:...|\"SciShow\"|\"scienc...| 223871|  8421|     191|         1214|https://i.ytimg.c...|            False|           False|                 False|Thanks to 23AndMe...|\n","+-----------+-------------+--------------------+--------------------+-----------+--------------------+--------------------+-------+------+--------+-------------+--------------------+-----------------+----------------+----------------------+--------------------+\n","only showing top 20 rows\n","\n","root\n"," |-- video_id: string (nullable = true)\n"," |-- trending_date: string (nullable = true)\n"," |-- title: string (nullable = true)\n"," |-- channel_title: string (nullable = true)\n"," |-- category_id: string (nullable = true)\n"," |-- publish_time: string (nullable = true)\n"," |-- tags: string (nullable = true)\n"," |-- views: string (nullable = true)\n"," |-- likes: string (nullable = true)\n"," |-- dislikes: string (nullable = true)\n"," |-- comment_count: string (nullable = true)\n"," |-- thumbnail_link: string (nullable = true)\n"," |-- comments_disabled: string (nullable = true)\n"," |-- ratings_disabled: string (nullable = true)\n"," |-- video_error_or_removed: string (nullable = true)\n"," |-- description: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["#### Otra alternativa para leer desde una fuente de datos parquet en este caso"],"metadata":{"id":"z0fseZtm2Ojd"}},{"cell_type":"code","source":["# Otra alternativa para leer desde una fuente de datos parquet en este caso\n","df6 = spark.read.format('parquet').load('dataPARQUET.parquet')\n","df6.printSchema()"],"metadata":{"id":"GfDFjhwO2QCK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723490705654,"user_tz":180,"elapsed":477,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"7a034327-13fe-4177-a6ca-4871b05fa443"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- video_id: string (nullable = true)\n"," |-- trending_date: string (nullable = true)\n"," |-- title: string (nullable = true)\n"," |-- channel_title: string (nullable = true)\n"," |-- category_id: string (nullable = true)\n"," |-- publish_time: string (nullable = true)\n"," |-- tags: string (nullable = true)\n"," |-- views: string (nullable = true)\n"," |-- likes: string (nullable = true)\n"," |-- dislikes: string (nullable = true)\n"," |-- comment_count: string (nullable = true)\n"," |-- thumbnail_link: string (nullable = true)\n"," |-- comments_disabled: string (nullable = true)\n"," |-- ratings_disabled: string (nullable = true)\n"," |-- video_error_or_removed: string (nullable = true)\n"," |-- description: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["### Trabajo con columnas"],"metadata":{"id":"cMzjqaqw4zET"}},{"cell_type":"code","source":["# Trabajo con columnas\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('dataPARQUET.parquet')\n","df.printSchema()"],"metadata":{"id":"taQMwL6m4zcr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723491576368,"user_tz":180,"elapsed":354,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"03eb358e-a3fd-4712-d2c9-2806c692e670"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- video_id: string (nullable = true)\n"," |-- trending_date: string (nullable = true)\n"," |-- title: string (nullable = true)\n"," |-- channel_title: string (nullable = true)\n"," |-- category_id: string (nullable = true)\n"," |-- publish_time: string (nullable = true)\n"," |-- tags: string (nullable = true)\n"," |-- views: string (nullable = true)\n"," |-- likes: string (nullable = true)\n"," |-- dislikes: string (nullable = true)\n"," |-- comment_count: string (nullable = true)\n"," |-- thumbnail_link: string (nullable = true)\n"," |-- comments_disabled: string (nullable = true)\n"," |-- ratings_disabled: string (nullable = true)\n"," |-- video_error_or_removed: string (nullable = true)\n"," |-- description: string (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["# Primera alternativa para referirnos a las columnas\n","df.select('title').show()"],"metadata":{"id":"Itiv-LLa7MOv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723491582178,"user_tz":180,"elapsed":333,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"e808eb05-4af8-4fbf-945c-ae0ffe34df79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+\n","|               title|\n","+--------------------+\n","|WE WANT TO TALK A...|\n","|The Trump Preside...|\n","|Racist Superman |...|\n","|Nickelback Lyrics...|\n","|I Dare You: GOING...|\n","|2 Weeks with iPho...|\n","|Roy Moore & Jeff ...|\n","|5 Ice Cream Gadge...|\n","|The Greatest Show...|\n","|Why the rise of t...|\n","|Dion Lewis' 103-Y...|\n","|(SPOILERS) 'Shiva...|\n","|Marshmello - Bloc...|\n","|Which Countries A...|\n","|SHOPPING FOR NEW ...|\n","|    The New SpotMini|\n","|One Change That W...|\n","|How does your bod...|\n","|HomeMade Electric...|\n","|Founding An Inbre...|\n","+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["# Segunda alternativa\n","from pyspark.sql.functions import col\n","\n","df.select(col('title')).show()"],"metadata":{"id":"ZhBeWLiY7MG1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723491587229,"user_tz":180,"elapsed":348,"user":{"displayName":"Nahuel Lopez","userId":"06859695819217714267"}},"outputId":"dc336673-d2d8-4160-8c5c-53b244bfc9ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+\n","|               title|\n","+--------------------+\n","|WE WANT TO TALK A...|\n","|The Trump Preside...|\n","|Racist Superman |...|\n","|Nickelback Lyrics...|\n","|I Dare You: GOING...|\n","|2 Weeks with iPho...|\n","|Roy Moore & Jeff ...|\n","|5 Ice Cream Gadge...|\n","|The Greatest Show...|\n","|Why the rise of t...|\n","|Dion Lewis' 103-Y...|\n","|(SPOILERS) 'Shiva...|\n","|Marshmello - Bloc...|\n","|Which Countries A...|\n","|SHOPPING FOR NEW ...|\n","|    The New SpotMini|\n","|One Change That W...|\n","|How does your bod...|\n","|HomeMade Electric...|\n","|Founding An Inbre...|\n","+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["### Transformaciones, funciones, select y selectExpr"],"metadata":{"id":"3ev9NTdP40P-"}},{"cell_type":"code","source":["# Transformaciones - funciones select y selectExpr\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('datos.parquet')\n","df.printSchema()"],"metadata":{"id":"i3nOYMyq40kC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Con select"],"metadata":{"id":"V6VSBnqU8B8C"}},{"cell_type":"code","source":["df.select(col('video_id')).show()"],"metadata":{"id":"KFhzaZlq721d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.select('video_id', 'trending_date').show()"],"metadata":{"id":"HqPXvx727mxx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Esta vía nos dará error\n","df.select(\n","    'likes',\n","    'dislikes',\n","    ('likes' - 'dislikes')\n",").show()"],"metadata":{"id":"wyKq9xl67mrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Forma correcta\n","df.select(\n","    col('likes'),\n","    col('dislikes'),\n","    (col('likes') - col('dislikes')).alias('aceptacion')\n",").show()"],"metadata":{"id":"9sTFbyFy7mlL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Con selectExpr"],"metadata":{"id":"0MXbdTiD8Fcw"}},{"cell_type":"code","source":["# selectExpr\n","df.selectExpr('likes', 'dislikes', '(likes - dislikes) as aceptacion').show()\n","df.selectExpr(\"count(distinct(video_id)) as videos\").show()"],"metadata":{"id":"O0R4ssbi7mcU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformaciones, funciones, filter y where"],"metadata":{"id":"hMn1H_5B40-i"}},{"cell_type":"code","source":["# Transformaciones - funciones filter y where\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('datos.parquet')\n","df.show()"],"metadata":{"id":"8w-rJRPa41Q5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Filter y where"],"metadata":{"id":"GtNJIU-B8cfR"}},{"cell_type":"code","source":["df.filter(col('video_id') == '2kyS6SvSYSE').show()"],"metadata":{"id":"NjsXUDQ_8jmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = spark.read.parquet('datos.parquet').where(col('trending_date') != '17.14.11')\n","df1.show()"],"metadata":{"id":"oH2sXYod8kKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2 = spark.read.parquet('datos.parquet').where(col('likes') > 5000)"],"metadata":{"id":"Ezc0rUEM8nA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.filter((col('trending_date') != '17.14.11') & (col('likes') > 7000)).show()"],"metadata":{"id":"mAr6YLED8vvx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.filter(col('trending_date') != '17.14.11').filter(col('likes') > 7000).show()"],"metadata":{"id":"3GqiJ-fG8vll"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformaciones, funciones, distinct y dropDuplicates"],"metadata":{"id":"sv-Wjy7a41sK"}},{"cell_type":"code","source":["# Transformaciones - funciones distinct y dropDuplicates\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('./data')"],"metadata":{"id":"TB3EBcXl42JU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### distinct"],"metadata":{"id":"KREUBu7_9R-8"}},{"cell_type":"code","source":["# distinct\n","df_sin_duplicados = df.distinct()\n","print('El conteo del dataframe original es {}'.format(df.count()))\n","print('El conteo del dataframe sin duplicados es {}'.format(df_sin_duplicados.count()))"],"metadata":{"id":"PY0YipFe9VlZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### dropDuplicates"],"metadata":{"id":"Cz-eyNo89beE"}},{"cell_type":"code","source":["# función dropDuplicates\n","dataframe = spark.createDataFrame([(1, 'azul', 567), (2, 'rojo', 487), (1, 'azul', 345), (2, 'verde', 783)]).toDF('id', 'color', 'importe')\n","dataframe.show()"],"metadata":{"id":"X6eMg2Iy9eXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe.dropDuplicates(['id', 'color']).show()"],"metadata":{"id":"oU640Dp19nHX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformaciones, funciones, sort y orderBy"],"metadata":{"id":"JxtHlLfX5dDh"}},{"cell_type":"code","source":["# Transformaciones - funciones sort y orderBy\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","from pyspark.sql.functions import desc\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = (spark.read.parquet('./data')\n","    .select(col('likes'), col('views'), col('video_id'), col('dislikes'))\n","    .dropDuplicates(['video_id'])\n",")\n","\n","df.show()"],"metadata":{"id":"jCMT3N3X5dk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sort\n","df.sort('likes').show()\n","df.sort(desc('likes')).show()"],"metadata":{"id":"yjrZArtC_Wmg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# función orderBy\n","df.orderBy(col('views')).show()\n","df.orderBy(col('views').desc()).show()"],"metadata":{"id":"N2kzGxQ7_WdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe = spark.createDataFrame([(1, 'azul', 568), (2, 'rojo', 235), (1, 'azul', 456), (2, 'azul', 783)]).toDF('id', 'color', 'importe')\n","dataframe.show()"],"metadata":{"id":"h-9yDi_y_WXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe.orderBy(col('color').desc(), col('importe')).show()"],"metadata":{"id":"SbI0dJKB_WSX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# funcion limit\n","top_10 = df.orderBy(col('views').desc()).limit(10)\n","top_10.show()"],"metadata":{"id":"LgyMdJts_oA4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformaciones, funciones, withColumn y withColumnRenamed"],"metadata":{"id":"dNxdKTPc5gwW"}},{"cell_type":"code","source":["# Transformaciones - funciones withColumn y withColumnRenamed\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('./data')"],"metadata":{"id":"O_Nsze205hCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# withColumn\n","df_valoracion = df.withColumn('valoracion', col('likes') - col('dislikes'))\n","df_valoracion.printSchema()\n","df_valoracion1 = (df.withColumn('valoracion', col('likes') - col('dislikes'))\n","                    .withColumn('res_div', col('valoracion') % 10)\n",")\n","\n","df_valoracion1.printSchema()\n","df_valoracion1.select(col('likes'), col('dislikes'), col('valoracion'), col('res_div')).show()"],"metadata":{"id":"zdog36UZ_9on"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# withColumnRenamed\n","df_renombrado = df.withColumnRenamed('video_id', 'id')\n","df_renombrado.printSchema()\n","df_error = df.withColumnRenamed('nombre_que_no_existe', 'otro_nombre')\n","df_error.printSchema()"],"metadata":{"id":"QCSvjIKb_9em"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformaciones, funciones, drop, sample, randomSplit"],"metadata":{"id":"tuC-i9NC5hhl"}},{"cell_type":"code","source":["# Transformaciones - funciones drop, sample y randomSplit\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('./data')\n","df.printSchema()"],"metadata":{"id":"fw-OpEQw5h0z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drop\n","df_util = df.drop('comments_disabled')\n","df_util.printSchema()\n","\n","df_util = df.drop('comments_disabled', 'ratings_disabled', 'thumbnail_link')\n","df_util.printSchema()\n","\n","df_util = df.drop('comments_disabled', 'ratings_disabled', 'thumbnail_link', 'cafe')\n","df_util.printSchema()"],"metadata":{"id":"uY8K10hZASQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sample\n","df_muestra = df.sample(0.8)\n","num_filas = df.count()\n","num_filas_muestra = df_muestra.count()\n","\n","print('El 80% de filas del dataframe original es {}'.format(num_filas - (num_filas*0.2)))\n","print('El numero de filas del dataframe muestra es {}'.format(num_filas_muestra))\n","\n","df_muestra = df.sample(fraction=0.8, seed=1234)\n","df_muestra = df.sample(withReplacement=True, fraction=0.8, seed=1234)"],"metadata":{"id":"IrfQL2NYATKg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# randomSplit\n","train, test = df.randomSplit([0.8, 0.2], seed=1234)\n","train, validation, test = df.randomSplit([0.6, 0.2, 0.2], seed=1234)\n","\n","train.count()\n","validation.count()\n","test.count()"],"metadata":{"id":"80bk12ocAS_o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Trabajo con datos incorrectos faltantes"],"metadata":{"id":"BXFU-VIW5r70"}},{"cell_type":"code","source":["# Trabajo con datos incorrectos o faltantes\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('./data/')\n","df.count()"],"metadata":{"id":"n_D1FPLK5sTo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.na.drop().count()"],"metadata":{"id":"HLjW-ZT-AwWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.na.drop('any').count()"],"metadata":{"id":"Q0lUE_hyAwBx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dropna().count()"],"metadata":{"id":"bxxlsxBhAv5p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.na.drop(subset=['views']).count()"],"metadata":{"id":"n532f6PmAvzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.na.drop(subset=['views', 'dislikes']).count()"],"metadata":{"id":"Lu8ljks7AvtX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.orderBy(col('views')).select(col('views'), col('likes'), col('dislikes')).show()"],"metadata":{"id":"DAn7R8pAAvn2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.fillna(0).orderBy(col('views')).select(col('views'), col('likes'), col('dislikes')).show()"],"metadata":{"id":"5cNFfGvbAvh9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.fillna(0, subset=['likes', 'dislikes']).orderBy(col('views')).select(col('views'), col('likes'), col('dislikes')).show()"],"metadata":{"id":"EA2OE1P8AvcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"giA8FzDVAvXd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Acciones sobre un dataframe"],"metadata":{"id":"xmTSAMRa520e"}},{"cell_type":"code","source":["# Acciones sobre un dataframe en Spark SQL\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('./data/')"],"metadata":{"id":"kVgf-HeY53b6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show\n","df.show()\n","df.show(5)\n","df.show(5, truncate=False)"],"metadata":{"id":"j1GT2zRVBMBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# take\n","df.take(1)"],"metadata":{"id":"WSVOFu8XBL5s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# head\n","df.head(1)"],"metadata":{"id":"UmbV0K_uBLx8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# collect\n","df.select('likes').collect()"],"metadata":{"id":"IhK44_QXBLpd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Escritura de dataframes"],"metadata":{"id":"7Kyh21M159er"}},{"cell_type":"code","source":["# Escritura de DataFrames\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.read.parquet('./data/')"],"metadata":{"id":"wC0d5Ixx5-1I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = df.repartition(2)"],"metadata":{"id":"65Hfyrx3Bhpj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.write.format('csv').option('sep', '|').save()"],"metadata":{"id":"_bXHdU_iBhVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.coalesce(1).write.format('csv').option('sep', '|').save('./output/csv1')"],"metadata":{"id":"CAB9K3mjBhBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"id":"9T8VexbsBsRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.select('comments_disabled').distinct().show()"],"metadata":{"id":"1xodxMKgBg5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_limpio = df.filter(col('comments_disabled').isin('True', 'False'))"],"metadata":{"id":"KVGvspOFBgyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_limpio.write.partitionBy('comments_disabled').parquet('./output/parquet')"],"metadata":{"id":"X_mjutnZBgqT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Lectura 1"],"metadata":{"id":"IKAJRd7E6Cvd"}},{"cell_type":"code","source":["# Instalar SDK java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Spark\n","!wget -q https://archive.apache.org/dist/spark/spark-3.3.4/spark-3.3.4-bin-hadoop3.tgz\n","\n","# Descomprimir la version de Spark\n","!tar xf spark-3.3.4-bin-hadoop3.tgz\n","\n","# Establecer las variables de entorno\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.4-bin-hadoop3\"\n","\n","# Descargar findspark\n","!pip install -q findspark\n","\n","# Instalar dotenv para manejar las credenciales\n","!pip install python-dotenv\n","\n","# Extraer las credenciales del archivo .env a un diccionario de Python\n","from dotenv import dotenv_values\n","\n","config = dotenv_values(\".env\")\n","\n","# Crear la sesión de Spark con las configuraciones necesarias para conectarse a AWS S3\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = (SparkSession\n","         .builder\n","         .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk-bundle:1.11.469\")\n","         .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n","         .getOrCreate()\n","         )\n","\n","# Extraer las credenciales del diccionario\n","accessKeyId=config.get('ACCESS_KEY')\n","secretAccessKey=config.get('SECRET_ACCESS_KEY')\n","\n","# Establecer las configuraciones de Hodoop necesarias\n","sc = spark.sparkContext\n","\n","sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', accessKeyId)\n","sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secretAccessKey)\n","sc._jsc.hadoopConfiguration().set('fs.s3a.path.style.access', 'true')\n","sc._jsc.hadoopConfiguration().set('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n","sc._jsc.hadoopConfiguration().set('fs.s3a.endpoint', 's3.amazonaws.com')\n","\n","df = spark.read.parquet('s3a://josemtech/parquet')\n","df.show()"],"metadata":{"id":"NlmP8rfu6DXp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = spark.read.option('header', 'true').option('inferSchema', 'true').csv('s3a://josemtech/csv/')\n","df1.show()"],"metadata":{"id":"vOAUjZX2CGHJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.write.mode('overwrite').parquet('s3a://josemtech/salida')"],"metadata":{"id":"VTBCz4qjCHzH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Lectura 2"],"metadata":{"id":"eZWT-39D6Dxm"}},{"cell_type":"code","source":["# Instalar SDK java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Spark\n","!wget -q https://archive.apache.org/dist/spark/spark-3.3.4/spark-3.3.4-bin-hadoop3.tgz\n","\n","# Descomprimir la version de Spark\n","!tar xf spark-3.3.4-bin-hadoop3.tgz\n","\n","# Establecer las variables de entorno\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.4-bin-hadoop3\"\n","\n","# Descargar findspark\n","!pip install -q findspark\n","\n","# Extraer las credenciales desde los Secrets\n","from google.colab import userdata\n","\n","account_key = userdata.get('ACCOUNT_KEY')\n","\n","# Crear la sesión de Spark\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = (SparkSession.builder\n","         .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.6,com.microsoft.azure:azure-storage:8.6.6\")\n","         .config(\"spark.hadoop.fs.azure.account.key.josemtech.blob.core.windows.net\", account_key)\n","         .config(\"spark.hadoop.fs.wasbs.impl\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n","         .config(\"spark.hadoop.fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n","         .getOrCreate())"],"metadata":{"id":"p3kmrtj06ECj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lectura\n","df = spark.read.parquet(\"wasbs://spark-data@josemtech.blob.core.windows.net/parquet\")\n","df.show()"],"metadata":{"id":"4jS1hq3ZCYpQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Escritura\n","df.write.mode(\"overwrite\").parquet(\"wasbs://spark-data@josemtech.blob.core.windows.net/test/\")"],"metadata":{"id":"Wqzd90qfCYiR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Lectura 3"],"metadata":{"id":"hiM281oK6Ejv"}},{"cell_type":"code","source":["# Instalar SDK java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Spark\n","!wget -q https://archive.apache.org/dist/spark/spark-3.3.4/spark-3.3.4-bin-hadoop3.tgz\n","\n","# Descomprimir la version de Spark\n","!tar xf spark-3.3.4-bin-hadoop3.tgz\n","\n","# Establecer las variables de entorno\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.4-bin-hadoop3\"\n","\n","# Descargar findspark\n","!pip install -q findspark\n","\n","# Descargar el jar necesario para conectarse al bucket de GCP\n","!wget https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.9/gcs-connector-hadoop3-2.2.9-shaded.jar\n","\n","# Mover el jar descargado a la carpeta de jars de Spark\n","!mv gcs-connector-hadoop3-2.2.9-shaded.jar /content/spark-3.4.2-bin-hadoop3/jars\n","\n","# Crear la sesión de Spark\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","\n","spark = (SparkSession.builder\n","         .config(\"spark.hadoop.fs.gs.impl\",\"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n","         .config(\"google.cloud.auth.service.account.json.keyfile\",\"/content/pyspark.json\")\n","         .getOrCreate())\n","\n","df = spark.read.parquet('gs://josemtech/parquet')\n","df.show()"],"metadata":{"id":"tTqsnjZA6E0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.write.mode('overwrite').parquet('gs://josemtech/salida_parquet')"],"metadata":{"id":"m9gowNIlDBG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = spark.read.option('header', 'true').csv('gs://josemtech/csv')\n","df1.show()"],"metadata":{"id":"ygz2iQMnDA9N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.write.mode('overwrite').csv('gs://josemtech/salida_csv')"],"metadata":{"id":"0UFipWU9DA4E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Persistencia de dataframes"],"metadata":{"id":"XodAtT0L6FU-"}},{"cell_type":"code","source":["# Persistencia de DataFrames\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","from pyspark.storagelevel import StorageLevel\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df = spark.createDataFrame([(1, 'a'), (2, 'b'), (3, 'c')], ['id', 'valor'])\n","df.show()"],"metadata":{"id":"Q_67bz6G6FpR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.persist()"],"metadata":{"id":"LmL3gC57DZrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.unpersist()"],"metadata":{"id":"2Yh3dg-pDZjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.cache()"],"metadata":{"id":"PtC2pUaZDZby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.persist(StorageLevel.DISK_ONLY)"],"metadata":{"id":"tCnHqTE0DZUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.persist(StorageLevel.MEMORY_AND_DISK)"],"metadata":{"id":"xFc_oTMYDZNu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejercicios"],"metadata":{"id":"Ta4D8s6X6bQf"}},{"cell_type":"code","source":[],"metadata":{"id":"Cvh-rlMf6brM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d93Xay9kA95I"},"source":["-----------\n","## Fin Notebook\n","-----------"]}],"metadata":{"colab":{"collapsed_sections":["_zJeZZqpJu73","LccNQX8WMBtl","Jz_8wAjF-CZL","q5eOVSiKAhWl","4xTFXrXNSG_b","AONlSDOoxVza","OMvFeqRfvYKZ","aMowH838zAg-","0MXbdTiD8Fcw","hMn1H_5B40-i","sv-Wjy7a41sK","JxtHlLfX5dDh","dNxdKTPc5gwW","tuC-i9NC5hhl","BXFU-VIW5r70","xmTSAMRa520e","7Kyh21M159er","IKAJRd7E6Cvd","eZWT-39D6Dxm","hiM281oK6Ejv"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}